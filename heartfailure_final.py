# -*- coding: utf-8 -*-
"""HeartFailure_Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1agvbteefLBoi4X4VXKDWRsfoXa09wdta

#**importing the libraries**
"""

# 1. to handle the data
import pandas as pd
import numpy as np

# 2. To Viusalize the data
import matplotlib.pyplot as plt
import seaborn as sns

# 3. To preprocess the data
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.model_selection import StratifiedKFold,GridSearchCV

# 4. For Classification task.
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
import xgboost as xgb

# 5. Metrics
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

"""#**reading and uploding the dataset**

"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("fedesoriano/heart-failure-prediction")

print("Path to dataset files:", path)

data= pd.read_csv("/kaggle/input/heart-failure-prediction/heart.csv")
df = data.copy()

"""#**Dataset Information**"""

df.head()

df.shape

df.columns

df.info()

data.describe().T

yes = data[data['HeartDisease'] == 1].describe().T
no = data[data['HeartDisease'] == 0].describe().T
colors = ['#F93822','#FDD20E']

fig,ax = plt.subplots(nrows = 1,ncols = 2,figsize = (5,5))
plt.subplot(1,2,1)
sns.heatmap(yes[['mean']],annot = True,cmap = colors,linewidths = 0.4,linecolor = 'black',cbar = False,fmt = '.2f',)
plt.title('Heart Disease');

plt.subplot(1,2,2)
sns.heatmap(no[['mean']],annot = True,cmap = colors,linewidths = 0.4,linecolor = 'black',cbar = False,fmt = '.2f')
plt.title('No Heart Disease');

fig.tight_layout(pad = 2)
#Mean values of all the features for cases of heart diseases and non-heart diseases.

df.isnull().sum()

"""#**Data Analysis**"""

plt.figure(figsize=(15,10))
sns.pairplot(df,hue="HeartDisease")
plt.title("Looking for Insites in Data")
plt.legend("HeartDisease")
plt.tight_layout()
plt.plot()

numeric_df = df.select_dtypes(include=["int64", "float64"])
corr = numeric_df.corr()
plt.figure(figsize=(15,15))
sns.heatmap(corr, cbar=True, square= True, fmt='.1f', annot=True, annot_kws={'size':15}, cmap='Greens')

"""#**Training our Machine Learning Model**

##**Using Logistic Regression**
"""

target = 'HeartDisease'
feature_cols = [col for col in df.columns if col != target]

categorical_cols = df.select_dtypes(include='object').columns
for col in categorical_cols:
    df[col] = LabelEncoder().fit_transform(df[col])

X = df[feature_cols]
y = df[target]

# Cross-validation
kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
acc_logreg = []
fold_num = 1

for train_idx, val_idx in kf.split(X, y):
    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

    #scaling the dataset
    scaler = MinMaxScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)

    # Logistic Regression model
    model = LogisticRegression(max_iter=1000, random_state=42)
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_val_scaled)


    acc = accuracy_score(y_val, y_pred)
    acc_logreg.append(acc)

    print(f"Fold {fold_num} Accuracy: {acc:.4f}")
    print(classification_report(y_val, y_pred, digits=4))
    fold_num += 1


print(f"Mean Accuracy: {np.mean(acc_logreg):.4f}")

"""##**Using SVM(Support Vector Machines)**"""

acc_svm_rbf = []
for train_idx, val_idx in kf.split(X, y):
    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

    # scaling the dataset
    scaler = MinMaxScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)

    # svm with rbf kernel
    model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_val_scaled)

    acc = accuracy_score(y_val, y_pred)
    acc_svm_rbf.append(acc)

    print(f"Fold {fold_num} Accuracy: {acc:.4f}")
    print(classification_report(y_val, y_pred, digits=4))
    fold_num += 1

print(f"Mean Accuracy: {np.mean(acc_svm_rbf):.4f}")

"""##**Using XGboost**"""

kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
acc_xgb = []
fold_num = 1

for train_idx, val_idx in kf.split(X, y):
    # Split train and validation sets
    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

    # Scaling is optional for XGBoost but generally harmless
    scaler = MinMaxScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)

    # Initialize XGBoost classifier
    model = xgb.XGBClassifier(
        n_estimators=100,
        learning_rate=0.1,
        max_depth=3,
        use_label_encoder=False,
        eval_metric='logloss',
        random_state=42
    )

    # Train the model
    model.fit(X_train_scaled, y_train)

    # Make predictions
    y_pred = model.predict(X_val_scaled)

    # Compute accuracy and classification report
    acc = accuracy_score(y_val, y_pred)
    acc_xgb.append(acc)

    print(f"Fold {fold_num} Accuracy: {acc:.4f}")
    print(classification_report(y_val, y_pred, digits=4))
    fold_num += 1

# Compute mean accuracy across all folds
print(f"Mean Accuracy: {np.mean(acc_xgb):.4f}")

"""##**Using K-nearest Neighbors**"""

# Features and target
X = df[feature_cols]
y = df[target]

# Feature scaling (essential for KNN)
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

# Define the KNN model
knn = KNeighborsClassifier()

# Define the parameter grid for k
param_grid = {'n_neighbors': list(range(1, 21))}  # Testing k from 1 to 20

# Use Stratified 5-Fold cross-validation
kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# GridSearchCV to find the best k
grid_search = GridSearchCV(
    estimator=knn,
    param_grid=param_grid,
    cv=kf,
    scoring='accuracy'
)

# Fit GridSearch
grid_search.fit(X_scaled, y)

# Best k and corresponding accuracy
print("Best k:", grid_search.best_params_['n_neighbors'])
print("Best cross-validated accuracy:", grid_search.best_score_)

# Detailed classification report using the best model
best_knn = grid_search.best_estimator_
y_pred = best_knn.predict(X_scaled)
print(classification_report(y, y_pred, digits=4))

acc_knn = []
fold_num = 1

for train_idx, val_idx in kf.split(X, y):
    # Split train and validation sets
    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

    # Feature scaling is essential for KNN
    scaler = MinMaxScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)

    # Initialize KNN classifier
    model = KNeighborsClassifier(n_neighbors=16)  # You can tune k

    # Train the model
    model.fit(X_train_scaled, y_train)

    # Make predictions
    y_pred = model.predict(X_val_scaled)

    # Compute accuracy and classification report
    acc = accuracy_score(y_val, y_pred)
    acc_knn.append(acc)

    print(f"Fold {fold_num} Accuracy: {acc:.4f}")
    print(classification_report(y_val, y_pred, digits=4))
    fold_num += 1

# Compute mean accuracy across all folds
print(f"Mean Accuracy: {np.mean(acc_knn):.4f}")

"""##**Using Random Forest Classifier**"""

# 5-Fold Stratified Cross-Validation
kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
acc_rf = []
fold_num = 1

for train_idx, val_idx in kf.split(X, y):
    # Split train and validation sets
    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

    # Initialize Random Forest classifier
    model = RandomForestClassifier(
        n_estimators=100,
        max_depth=None,
        random_state=42
    )

    # Train the model
    model.fit(X_train, y_train)

    # Make predictions
    y_pred = model.predict(X_val)

    # Compute accuracy and classification report
    acc = accuracy_score(y_val, y_pred)
    acc_rf.append(acc)

    print(f"Fold {fold_num} Accuracy: {acc:.4f}")
    print(classification_report(y_val, y_pred, digits=4))
    fold_num += 1

# Compute mean accuracy across all folds
print(f"Mean Accuracy: {np.mean(acc_rf):.4f}")

"""
# 📊 Model Evaluation & Comparison

This section trains multiple **classification models** on the Heart Failure dataset and compares them using **Accuracy, Precision, Recall, F1-score**, and **ROC-AUC**.  
It also selects the **best model** based on F1-score and explains **why** it is a good fit for this dataset.
"""

# =============================
# Model Evaluation & Comparison
# =============================

import numpy as np
import pandas as pd

from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix
)

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

import matplotlib.pyplot as plt

# -------- Helper: attempt to find the dataframe --------
# We expect a pandas DataFrame with the Kaggle columns and target 'HeartDisease'.
# Try common variable names; otherwise try to load 'heart.csv' if present.
df_candidate = None
for name, val in list(globals().items()):
    if hasattr(val, "head") and hasattr(val, "columns"):
        cols = set(str(c) for c in val.columns)
        if "HeartDisease" in cols or "target" in cols:
            df_candidate = val
            break

if df_candidate is None:
    # Attempt to load default Kaggle file name if available
    try:
        import os
        if os.path.exists("heart.csv"):
            df_candidate = pd.read_csv("heart.csv")
        elif os.path.exists("./data/heart.csv"):
            df_candidate = pd.read_csv("./data/heart.csv")
        else:
            raise FileNotFoundError("Could not find a DataFrame or 'heart.csv'. Please ensure data is loaded as df/heart.csv.")
    except Exception as e:
        print("❗ Data not found automatically. Please load your dataframe into a variable (e.g., df) with target column 'HeartDisease'.")
        raise e

df = df_candidate.copy()

# Normalize column names (strip spaces etc.)
df.columns = [str(c).strip() for c in df.columns]

# Identify target column
target_col = "HeartDisease" if "HeartDisease" in df.columns else ("target" if "target" in df.columns else None)
if target_col is None:
    raise ValueError("Target column not found. Expected 'HeartDisease' or 'target'. Found: %s" % list(df.columns))

# Separate X, y
X = df.drop(columns=[target_col])
y = df[target_col].astype(int)

# Identify categorical and numeric columns by dtype + known names in Kaggle dataset
known_cats = ["Sex","ChestPainType","RestingECG","ExerciseAngina","ST_Slope"]
categorical_cols = [c for c in X.columns if (str(X[c].dtype) in ("object","category")) or (c in known_cats)]
numeric_cols = [c for c in X.columns if c not in categorical_cols]

# Preprocessors
categorical_transformer = OneHotEncoder(handle_unknown="ignore", sparse_output=False)
numeric_scaler = StandardScaler()

# Pipelines per model
# For linear/SVM/KNN we benefit from scaling numeric features.
preprocess_scaled = ColumnTransformer(
    transformers=[
        ("cat", categorical_transformer, categorical_cols),
        ("num", numeric_scaler, numeric_cols)
    ],
    remainder="drop",
)

# For tree-based/GaussianNB: trees don't need scaling; NB can work with scaled or unscaled; we still OHE categoricals.
preprocess_no_scale = ColumnTransformer(
    transformers=[
        ("cat", categorical_transformer, categorical_cols),
        ("num", "passthrough", numeric_cols)
    ],
    remainder="drop",
)

models = {
    "LogisticRegression": Pipeline([
        ("prep", preprocess_scaled),
        ("clf", LogisticRegression(max_iter=2000, n_jobs=None, class_weight=None))
    ]),
    "KNN": Pipeline([
        ("prep", preprocess_scaled),
        ("clf", KNeighborsClassifier(n_neighbors=5))
    ]),
    "SVM (RBF)": Pipeline([
        ("prep", preprocess_scaled),
        ("clf", SVC(kernel="rbf", probability=True))
    ]),
    "NaiveBayes": Pipeline([
        ("prep", preprocess_no_scale),
        ("clf", GaussianNB())
    ]),
    "DecisionTree": Pipeline([
        ("prep", preprocess_no_scale),
        ("clf", DecisionTreeClassifier(random_state=42))
    ]),
    "RandomForest": Pipeline([
        ("prep", preprocess_no_scale),
        ("clf", RandomForestClassifier(n_estimators=300, random_state=42))
    ]),
}

# Train/validation split (stratified)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

results = []

for name, pipe in models.items():
    pipe.fit(X_train, y_train)
    y_pred = pipe.predict(X_test)

    # Probabilities for ROC-AUC if available
    if hasattr(pipe.named_steps[list(pipe.named_steps.keys())[-1]], "predict_proba"):
        y_proba = pipe.predict_proba(X_test)[:, 1]
        roc = roc_auc_score(y_test, y_proba)
    else:
        # fallback using decision function or set to NaN
        if hasattr(pipe.named_steps[list(pipe.named_steps.keys())[-1]], "decision_function"):
            from sklearn.metrics import roc_auc_score
            scores = pipe.decision_function(X_test)
            # Convert to probability-like via ranking; or compute ROC on scores directly
            roc = roc_auc_score(y_test, scores)
        else:
            roc = np.nan

    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, zero_division=0)
    rec = recall_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)

    results.append({
        "Model": name,
        "Accuracy": acc,
        "Precision": prec,
        "Recall": rec,
        "F1": f1,
        "ROC_AUC": roc
    })

results_df = pd.DataFrame(results).sort_values(by=["F1","Accuracy"], ascending=False).reset_index(drop=True)
display(results_df)

# Save results
results_df.to_csv("model_comparison_results.csv", index=False)

# Plot Accuracy Bar Chart
plt.figure(figsize=(8,5))
plt.bar(results_df["Model"], results_df["Accuracy"])
plt.title("Model Accuracy Comparison")
plt.ylabel("Accuracy")
plt.xticks(rotation=30, ha="right")
plt.tight_layout()
plt.show()

# Select best by F1
best_row = results_df.iloc[0]
best_model_name = str(best_row["Model"])
print(f"\n🏆 Best model by F1-score: {best_model_name}")
print(best_row)

# Reasoning helper
reason = ""
if "RandomForest" in best_model_name:
    reason = (
        "- Handles mixed numeric/categorical features well via one-hot encoding.\n"
        "- Robust to non-linear relationships and outliers.\n"
        "- Built-in ensembling reduces variance and overfitting compared to a single tree.\n"
    )
elif "SVM" in best_model_name:
    reason = (
        "- RBF kernel captures complex, non-linear decision boundaries.\n"
        "- Works well with standardized features and moderate dimensions after one-hot encoding.\n"
        "- Often strong on medium-sized tabular datasets with clear margin separation.\n"
    )
elif "LogisticRegression" in best_model_name:
    reason = (
        "- Interpretable baseline that performs well when the relationship is close to linear in log-odds.\n"
        "- Benefits from standardized numeric features and well-encoded categoricals.\n"
    )
elif "KNN" in best_model_name:
    reason = (
        "- Non-parametric; good when local neighborhoods are informative.\n"
        "- Requires feature scaling; sensitive to irrelevant features and class imbalance.\n"
    )
elif "DecisionTree" in best_model_name:
    reason = (
        "- Captures non-linearities and interactions; interpretable via tree structure.\n"
        "- May overfit; pruning or ensembles like RandomForest often improve generalization.\n"
    )
elif "NaiveBayes" in best_model_name:
    reason = (
        "- Simple and fast baseline; can work well if feature independence roughly holds.\n"
        "- May underperform when strong feature interactions/non-linearities exist.\n"
    )

print("\n🔎 Why this model is a good fit:\n" + reason)

# Show classification report and confusion matrix for the best model
best_pipe = models[best_model_name]
y_pred_best = best_pipe.predict(X_test)
print("\nClassification Report (Best Model):\n")
print(classification_report(y_test, y_pred_best, digits=4))

cm = confusion_matrix(y_test, y_pred_best)
print("Confusion Matrix:")
print(cm)

"""# **Model Comparison & Results**
In this section, we will compare all trained models based on multiple metrics (Accuracy, Precision, Recall, F1 Score, and ROC-AUC). This helps us select the best-performing algorithm for the Heart Failure Prediction dataset.

"""

# Model Comparison Section

# Import required libraries
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import pandas as pd
import matplotlib.pyplot as plt

# Dictionary to store model results
results = []

# Loop through all trained models and evaluate them
for name, model in models.items():  # models should be a dictionary like {"Logistic Regression": log_model, ...}
    y_pred = model.predict(X_test)

    # Calculate metrics
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred)
    rec = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])

    # Save results
    results.append({
        "Model": name,
        "Accuracy": acc,
        "Precision": prec,
        "Recall": rec,
        "F1 Score": f1,
        "ROC-AUC": auc
    })

# Convert results into a DataFrame
results_df = pd.DataFrame(results)

# Sort models by F1 Score (or any metric you want)
results_df = results_df.sort_values(by="F1 Score", ascending=False)

# Show results
print("✅ Model Comparison Results:")
display(results_df)

# Save results to CSV (optional, for GitHub repository)
results_df.to_csv("model_comparison_results.csv", index=False)

# Plot a bar chart for better visualization
plt.figure(figsize=(10,6))
results_df.set_index("Model")[["Accuracy","Precision","Recall","F1 Score","ROC-AUC"]].plot(kind="bar")
plt.title("Model Performance Comparison")
plt.ylabel("Score")
plt.ylim(0,1)
plt.legend(loc="lower right")
plt.grid(axis="y")
plt.show()

"""#**Conclusion**

# 🩺 Heart Failure Prediction – Conclusion  

In this project, we explored different **machine learning algorithms** for predicting heart failure risk, including:  

- 🔹 Logistic Regression  
- 🔹 K-Nearest Neighbors (KNN)  
- 🔹 Support Vector Machine (SVM)  
- 🔹 Decision Tree  
- 🔹 Random Forest  

---

## 📊 Model Comparison  
Each model was evaluated using **Accuracy, Precision, Recall, F1-score, and ROC-AUC**.  
Among all, the **🌲 Random Forest Classifier** achieved the **best overall performance**, striking a strong balance between **recall** (catching most positive cases) and **precision** (avoiding false alarms).  

---

## ✅ Why Random Forest Works Best
- Handles both **linear & non-linear** patterns  
- Reduces **overfitting** compared to a single decision tree  
- Provides **feature importance** → helpful for medical interpretation  

---

## 🏁 Final Takeaway  
While **Random Forest** was the top-performing model, **Logistic Regression** also showed good results and remains valuable when **simplicity & interpretability** are essential (e.g., in clinical decision-making).  

⚡️ **Bottom line:** For this dataset, ensemble models like Random Forest are most effective, but real-world healthcare applications must balance **accuracy, interpretability, and computational cost**.
"""